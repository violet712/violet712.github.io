{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "assert tf.__version__.startswith('2.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "title_data = np.random.randint(2, size=(4))\n",
    "print(title_data.shape)\n",
    "print(title_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"model_8\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\vscodespace\\violet712.github.io\\my_algorithms\\test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mModel(x, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m inp \u001b[39m=\u001b[39m [[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m]]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model(inp)\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py:200\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInputs to a layer should be tensors. Got: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(input_spec):\n\u001b[1;32m--> 200\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m expects \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(input_spec)\u001b[39m}\u001b[39;00m\u001b[39m input(s),\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    201\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m but it received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m input tensors. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    202\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInputs received: \u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    203\u001b[0m \u001b[39mfor\u001b[39;00m input_index, (x, spec) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(inputs, input_spec)):\n\u001b[0;32m    204\u001b[0m   \u001b[39mif\u001b[39;00m spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Layer \"model_8\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>]"
     ]
    }
   ],
   "source": [
    "# this is a logistic regression in Keras\n",
    "x = keras.Input(shape=(2,))\n",
    "y = layers.Dense(16, activation='softmax')(x)\n",
    "model = keras.Model(x, y)\n",
    "\n",
    "inp = [[1, 2]]\n",
    "model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\vscodespace\\violet712.github.io\\my_algorithms\\test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m p \u001b[39m=\u001b[39m out(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(p)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "out = keras.Input(shape=(2,), name='out')\n",
    "x = [1, 2]\n",
    "x = x.numpy()\n",
    "p = out(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2 2 2 2 1 2 1 2 2]], shape=(1, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "s = tf.random.categorical([[-100000000000000., 2., 3.]], num_samples=10)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.6931472 -0.6931472]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor([[1 1 1 0 0]], shape=(1, 5), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "samples = tf.random.categorical(tf.math.log([[0.5, 0.5]]), 5)\n",
    "\n",
    "print(tf.math.log([[0.5, 0.5]]))\n",
    "print(samples)\n",
    "print(samples[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,762\n",
      "Trainable params: 2,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32,)) \n",
    "x = layers.Dense(64, activation='relu')(inputs) \n",
    "outputs = layers.Dense(10)(x) \n",
    "mlp = keras.Model(inputs, outputs)\n",
    "\n",
    "print(mlp.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(keras.Model):    \n",
    "    def __init__(self, **kwargs):     \n",
    "        super(MLP, self).__init__(**kwargs)     \n",
    "        self.dense_1 = layers.Dense(64, activation='relu')     \n",
    "        self.dense_2 = layers.Dense(10)    \n",
    "    \n",
    "    def call(self, inputs):     \n",
    "        x = self.dense_1(inputs)     \n",
    "        return self.dense_2(x)  # Instantiate the model. mlp = MLP() # Necessary to create the model's state. # The model doesn't have a state until it's called at least once. _ = mlp(tf.zeros((1, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,762\n",
      "Trainable params: 2,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp=MLP.call(Input(shape=(32,)))\n",
    "mlp.build(input_shape=(None, 32))\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " title (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " body (InputLayer)              [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 64)     640000      ['title[0][0]']                  \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 64)     640000      ['body[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 128)          98816       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 32)           12416       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " tags (InputLayer)              [(None, 12)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 172)          0           ['lstm[0][0]',                   \n",
      "                                                                  'lstm_1[0][0]',                 \n",
      "                                                                  'tags[0][0]']                   \n",
      "                                                                                                  \n",
      " priority (Dense)               (None, 1)            173         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " department (Dense)             (None, 4)            692         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,392,097\n",
      "Trainable params: 1,392,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_tags = 12  # Number of unique issue tags\n",
    "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4  # Number of departments for predictions\n",
    "\n",
    "title_input = keras.Input(\n",
    "    shape=(None,), name=\"title\"\n",
    ")  # Variable-length sequence of ints\n",
    "body_input = keras.Input(shape=(None,), name=\"body\")  # Variable-length sequence of ints\n",
    "tags_input = keras.Input(\n",
    "    shape=(num_tags,), name=\"tags\"\n",
    ")  # Binary vectors of size `num_tags`\n",
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = layers.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = layers.Dense(1, name=\"priority\")(x)\n",
    "# Stick a department classifier on top of the features\n",
    "department_pred = layers.Dense(num_departments, name=\"department\")(x)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = keras.Model(\n",
    "    inputs=[title_input, body_input, tags_input],\n",
    "    outputs=[priority_pred, department_pred],\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got: <keras.layers.core.dense.Dense object at 0x000001C702E94A90>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\vscodespace\\violet712.github.io\\my_algorithms\\test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m inputs \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39m784\u001b[39m,), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdigits\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m common \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDense(\u001b[39m64\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m actor \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mDense(\u001b[39m1\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msigmoid\u001b[39;49m\u001b[39m'\u001b[39;49m)(common)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m critic \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m)(common)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mModel(inputs\u001b[39m=\u001b[39minputs, outputs\u001b[39m=\u001b[39m[actor, critic])\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py:197\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m inputs:\n\u001b[0;32m    192\u001b[0m   \u001b[39m# Having a shape/dtype is the only commonality of the various tensor-like\u001b[39;00m\n\u001b[0;32m    193\u001b[0m   \u001b[39m# objects that may be passed. The most common kind of invalid type we are\u001b[39;00m\n\u001b[0;32m    194\u001b[0m   \u001b[39m# guarding for is a Layer instance (Functional API), which does not\u001b[39;00m\n\u001b[0;32m    195\u001b[0m   \u001b[39m# have a `shape` attribute.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInputs to a layer should be tensors. Got: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(input_spec):\n\u001b[0;32m    200\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m expects \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(input_spec)\u001b[39m}\u001b[39;00m\u001b[39m input(s),\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    201\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m but it received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m input tensors. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    202\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInputs received: \u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <keras.layers.core.dense.Dense object at 0x000001C702E94A90>"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name='digits')\n",
    "common = layers.Dense(64, activation='relu')\n",
    "actor = layers.Dense(1, activation='sigmoid')(common)\n",
    "critic = layers.Dense(1)(common)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=[actor, critic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 10)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(range(10))\n",
    "\n",
    "for i in range(10):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\vscodespace\\violet712.github.io\\my_algorithms\\test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# dy = 2x * dx\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m dy_dx \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(y, x)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(dy_dx\u001b[39m.\u001b[39;49mnumpy())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  # tape.watch(x)\n",
    "  y = x**2\n",
    "\n",
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.one_hot([0], depth=4)\n",
    "s = tf.Variable(s)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(s)\n",
    "    loss = tf.reduce_sum(s)\n",
    "    \n",
    "grad = tape.gradient(loss, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[var.name for var in tape.watched_variables()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(1,))\n",
    "outputs = layers.Dense(10)(inputs)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deep Q-Network Q(a, s)\n",
    "-----------------------\n",
    "TD Learning, Off-Policy, e-Greedy Exploration (GLIE).\n",
    "\n",
    "Q(S, A) <- Q(S, A) + alpha * (R + lambda * Q(newS, newA) - Q(S, A))\n",
    "delta_w = R + lambda * Q(newS, newA)\n",
    "\n",
    "See David Silver RL Tutorial Lecture 5 - Q-Learning for more details.\n",
    "\n",
    "Reference\n",
    "----------\n",
    "original paper: https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf\n",
    "EN: https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0#.5m3361vlw\n",
    "CN: https://zhuanlan.zhihu.com/p/25710327\n",
    "\n",
    "Note: Policy Network has been proved to be better than Q-Learning, see tutorial_atari_pong.py\n",
    "\n",
    "Environment\n",
    "-----------\n",
    "# The FrozenLake v0 environment\n",
    "https://gym.openai.com/envs/FrozenLake-v0\n",
    "The agent controls the movement of a character in a grid world. Some tiles of\n",
    "the grid are walkable, and others lead to the agent falling into the water.\n",
    "Additionally, the movement direction of the agent is uncertain and only partially\n",
    "depends on the chosen direction. The agent is rewarded for finding a walkable\n",
    "path to a goal tile.\n",
    "SFFF       (S: starting point, safe)\n",
    "FHFH       (F: frozen surface, safe)\n",
    "FFFH       (H: hole, fall to your doom)\n",
    "HFFG       (G: goal, where the frisbee is located)\n",
    "The episode ends when you reach the goal or fall in a hole. You receive a reward\n",
    "of 1 if you reach the goal, and zero otherwise.\n",
    "\n",
    "Prerequisites\n",
    "--------------\n",
    "tensorflow>=2.0.0a0\n",
    "tensorlayer>=2.0.0\n",
    "\n",
    "To run\n",
    "-------\n",
    "python tutorial_DQN.py --train/test\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import argparse\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "\n",
    "# add arguments in command  --train/test\n",
    "# 关于argparase的应用，可以看看我这篇知乎专栏：\n",
    "# 小段文讲清argparse模块基本用法[小番外]\n",
    "# https://zhuanlan.zhihu.com/p/111010774\n",
    "# 注意：原代码默认为test，我改为了train。\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Train or test neural net motor controller.')\n",
    "parser.add_argument('--train', dest='train', action='store_true', default=True)\n",
    "parser.add_argument('--test', dest='test', action='store_true', default=False)\n",
    "args = parser.parse_args()\n",
    "\n",
    "tl.logging.set_verbosity(tl.logging.DEBUG)\n",
    "\n",
    "#####################  hyper parameters  ####################\n",
    "lambd = .99             # 折扣率(decay factor)\n",
    "e = 0.1                 # epsilon-greedy算法参数，越大随机性越大，越倾向于探索行为。\n",
    "num_episodes = 10000    # 迭代次数\n",
    "render = False          # 是否渲染游戏\n",
    "running_reward = None\n",
    "\n",
    "##################### DQN ##########################\n",
    "\n",
    "## 把分类的数字表示，变成onehot表示。\n",
    "# 例如有4类，那么第三类变为：[0,0,1,0]的表示。\n",
    "\n",
    "\n",
    "def to_one_hot(i, n_classes=None):\n",
    "    a = np.zeros(n_classes, 'uint8')    # 这里先按照分类数量构建一个全0向量\n",
    "    a[i] = 1                            # 然后点亮需要onehot的位数。\n",
    "    return a\n",
    "\n",
    "\n",
    "## Define Q-network q(a,s) that ouput the rewards of 4 actions by given state, i.e. Action-Value Function.\n",
    "# encoding for state: 4x4 grid can be represented by one-hot vector with 16 integers.\n",
    "def get_model(inputs_shape):\n",
    "    '''\n",
    "    定义Q网络模型：\n",
    "    1. 注意输入的shape和输出的shape\n",
    "    2. W_init和b_init是模型在初始化的时候，控制初始化参数的随机。该代码中用正态分布，均值0，方差0.01的方式初始化参数。\n",
    "    '''\n",
    "    ni = tl.layers.Input(inputs_shape, name='observation')\n",
    "    nn = tl.layers.Dense(4, act=None, W_init=tf.random_uniform_initializer(\n",
    "        0, 0.01), b_init=None, name='q_a_s')(ni)\n",
    "    return tl.models.Model(inputs=ni, outputs=nn, name=\"Q-Network\")\n",
    "\n",
    "\n",
    "def save_ckpt(model):  # save trained weights\n",
    "    '''\n",
    "    保存参数\n",
    "    '''\n",
    "    tl.files.save_npz(model.trainable_weights, name='dqn_model.npz')\n",
    "\n",
    "\n",
    "def load_ckpt(model):  # load trained weights\n",
    "    '''\n",
    "    加载参数\n",
    "    '''\n",
    "    tl.files.load_and_assign_npz(name='dqn_model.npz', network=model)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    qnetwork = get_model([None, 16])  # 定义inputshape[None,16]。16是state数量\n",
    "    qnetwork.train()  # 调用tensorlayer的时候，需要标注这个模型是否可以训练。(再次吐槽tenorlayers...)\n",
    "    train_weights = qnetwork.trainable_weights  # 模型的参数\n",
    "\n",
    "    optimizer = tf.optimizers.SGD(learning_rate=0.1)  # 定义优化器\n",
    "    env = gym.make('FrozenLake-v0')  # 定义环境\n",
    "\n",
    "    # ======开始训练=======\n",
    "    if args.train:\n",
    "        t0 = time.time()\n",
    "        for i in range(num_episodes):\n",
    "            ## 重置环境初始状态\n",
    "            s = env.reset()\n",
    "            rAll = 0\n",
    "            for j in range(99):             # 最多探索99步。因为环境状态比较少，99步一般也够探索到最终状态了。\n",
    "                if render:\n",
    "                    env.render()\n",
    "\n",
    "                ## 把state放入network，计算Q值。\n",
    "                ## 注意，这里先把state进行onehote处理，这里注意解释下什么是onehot\n",
    "                ## 输出，这个状态下，所有动作的Q值，也就是说，是一个[None,4]大小的矩阵\n",
    "                allQ = qnetwork(np.asarray(\n",
    "                    [to_one_hot(s, 16)], dtype=np.float32)).numpy()\n",
    "\n",
    "                # 在矩阵中找最大的Q值的动作\n",
    "                a = np.argmax(allQ, 1)\n",
    "\n",
    "                # e-Greedy：如果小于epsilon，就智能体随机探索。否则，就用最大Q值的动作。\n",
    "                if np.random.rand(1) < e:\n",
    "                    a[0] = env.action_space.sample()\n",
    "\n",
    "                # 输入到环境，获得下一步的state，reward，done\n",
    "                s1, r, d, _ = env.step(a[0])\n",
    "\n",
    "                # 把new-state 放入，预测下一个state的**所有动作**的Q值。\n",
    "                Q1 = qnetwork(np.asarray(\n",
    "                    [to_one_hot(s1, 16)], dtype=np.float32)).numpy()\n",
    "\n",
    "                ##=======计算target=======\n",
    "                ## 构建更新target：\n",
    "                #    Q'(s,a) <- Q(s,a) + alpha(r + lambd * maxQ(s',a') - Q(s, a))\n",
    "                maxQ1 = np.max(Q1)          # 下一个状态中最大Q值.\n",
    "                # 用allQ(现在状态的Q值)构建更新的target。因为只有被选择那个动作才会被更新到。\n",
    "                targetQ = allQ\n",
    "                targetQ[0, a[0]] = r + lambd * maxQ1\n",
    "\n",
    "                ## 利用自动求导 进行更新。\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # 把s放入到Q网络，计算_qvalues。\n",
    "                    _qvalues = qnetwork(np.asarray(\n",
    "                        [to_one_hot(s, 16)], dtype=np.float32))\n",
    "                    #_qvalues和targetQ的差距就是loss。这里衡量的尺子是mse\n",
    "                    _loss = tl.cost.mean_squared_error(\n",
    "                        targetQ, _qvalues, is_mean=False)\n",
    "                # 同梯度带求导对网络参数求导\n",
    "                grad = tape.gradient(_loss, train_weights)\n",
    "                # 应用梯度到网络参数求导\n",
    "                optimizer.apply_gradients(zip(grad, train_weights))\n",
    "\n",
    "                # 累计reward，并且把s更新为newstate\n",
    "                rAll += r\n",
    "                s = s1\n",
    "\n",
    "                #更新epsilon，让epsilon随着迭代次数增加而减少。\n",
    "                #目的就是智能体越来越少进行“探索”\n",
    "                if d == True:\n",
    "                    e = 1. / ((i / 50) + 10)\n",
    "                    break\n",
    "\n",
    "            ## 这里的running_reward用于记载每一次更新的总和。为了能够更加看清变化，所以大部分是前面的。只有一部分是后面的。\n",
    "            running_reward = rAll if running_reward is None else running_reward * 0.99 + rAll * 0.01\n",
    "            # print(\"Episode [%d/%d] sum reward: %f running reward: %f took: %.5fs \" % \\\n",
    "            #     (i, num_episodes, rAll, running_reward, time.time() - episode_time))\n",
    "            print('Episode: {}/{}  | Episode Reward: {:.4f} | Running Average Reward: {:.4f}  | Running Time: {:.4f}'\n",
    "                  .format(i, num_episodes, rAll, running_reward,  time.time()-t0))\n",
    "        save_ckpt(qnetwork)  # save model\n",
    "\n",
    "    ##============这部分是正式游戏了========\n",
    "    # 这部分就不讲解了，和训练一样。只是少了epsilon-greedy。\n",
    "    if args.test:\n",
    "        t0 = time.time()\n",
    "        load_ckpt(qnetwork)  # load model\n",
    "        for i in range(num_episodes):\n",
    "            ## Reset environment and get first new observation\n",
    "            episode_time = time.time()\n",
    "            s = env.reset()  # observation is state, integer 0 ~ 15\n",
    "            rAll = 0\n",
    "            for j in range(99):  # step index, maximum step is 99\n",
    "                if render:\n",
    "                    env.render()\n",
    "\n",
    "                ## Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "                allQ = qnetwork(np.asarray(\n",
    "                    [to_one_hot(s, 16)], dtype=np.float32)).numpy()\n",
    "                a = np.argmax(allQ, 1)  # no epsilon, only greedy for testing\n",
    "\n",
    "                ## Get new state and reward from environment\n",
    "                s1, r, d, _ = env.step(a[0])\n",
    "                rAll += r\n",
    "                s = s1\n",
    "                ## Reduce chance of random action if an episode is done.\n",
    "                if d == True:\n",
    "                    #e = 1. / ((i / 50) + 10)  # reduce e, GLIE: Greey in the limit with infinite Exploration\n",
    "                    break\n",
    "\n",
    "            ## Note that, the rewards here with random action\n",
    "            running_reward = rAll if running_reward is None else running_reward * 0.99 + rAll * 0.01\n",
    "            # print(\"Episode [%d/%d] sum reward: %f running reward: %f took: %.5fs \" % \\\n",
    "            #     (i, num_episodes, rAll, running_reward, time.time() - episode_time))\n",
    "            print('Episode: {}/{}  | Episode Reward: {:.4f} | Running Average Reward: {:.4f}  | Running Time: {:.4f}'\n",
    "                  .format(i, num_episodes, rAll, running_reward,  time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.random.randint(0, 2, size=(2, 3))\n",
    "y_pred = np.random.random(size=(2, 3))\n",
    "loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "assert np.array_equal(\n",
    "    loss.numpy(), np.mean(np.square(y_true - y_pred), axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.zeros((6,))\n",
    "c = tf.ones((2,))\n",
    "b = a\n",
    "c = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2638d182245c591c0c7650a148f9b4622aaf18b8cff9e48ecf203e602cb4653c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
