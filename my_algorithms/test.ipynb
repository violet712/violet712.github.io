{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "logdir = 'logs/scalars'\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/test1\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "%tensorboard --logdir=logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1,100)\n",
    "y = x ** 2\n",
    "\n",
    "for i in range(100):\n",
    "    tf.summary.scalar('x', y[i], step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"model_8\" (type Functional).\n\nInput 0 of layer \"dense_10\" is incompatible with the layer: expected min_ndim=2, found ndim=0. Full shape received: ()\n\nCall arguments received:\n  • inputs=[['tf.Tensor(shape=(), dtype=float64)']]\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\vscodespace\\violet712.github.io\\my_algorithms\\test.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     tf\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mscalar(\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m, update(x[i], y[i]), step\u001b[39m=\u001b[39mi)\n",
      "\u001b[1;32md:\\vscodespace\\violet712.github.io\\my_algorithms\\test.ipynb Cell 3\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x \u001b[39m=\u001b[39m [[x]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     loss \u001b[39m=\u001b[39m (y \u001b[39m-\u001b[39m model(x)) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X42sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m grad \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, model\u001b[39m.\u001b[39mtrainable_variables)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grad, model\u001b[39m.\u001b[39mtrainable_variables))\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py:228\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    226\u001b[0m   ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[0;32m    227\u001b[0m   \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[1;32m--> 228\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    229\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    230\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    231\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    232\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    233\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"model_8\" (type Functional).\n\nInput 0 of layer \"dense_10\" is incompatible with the layer: expected min_ndim=2, found ndim=0. Full shape received: ()\n\nCall arguments received:\n  • inputs=[['tf.Tensor(shape=(), dtype=float64)']]\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(1,))\n",
    "l = layers.Dense(1, activation='linear')(inputs)\n",
    "model = keras.Model(inputs=inputs, outputs=l)\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "def update(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = (y - model(x)) ** 2\n",
    "    \n",
    "    grad = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "for i in range(100):\n",
    "    tf.summary.scalar('loss', update(x[i], y[i]), step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -0.77777778 -0.55555556 -0.33333333 -0.11111111  0.11111111\n",
      "  0.33333333  0.55555556  0.77777778  1.        ]\n",
      "[1.         0.60493827 0.30864198 0.11111111 0.01234568 0.01234568\n",
      " 0.11111111 0.30864198 0.60493827 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-3.6595562  3.584101 ]], shape=(1, 2), dtype=float32)\n",
      "[(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-3.6595562,  3.584101 ], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>)]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "var and grad do not have the same shape[2,1] [2] [Op:ResourceApplyAdam]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32md:\\vscodespace\\violet712.github.io\\my_algorithms\\test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m zipped \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(grad, x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X36sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlist\u001b[39m(zipped))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X36sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mapply_gradients(\u001b[39mzip\u001b[39;49m(grad, model\u001b[39m.\u001b[39;49mtrainable_variables))\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:671\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    668\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_gradients(grads_and_vars)\n\u001b[0;32m    669\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_gradients(grads_and_vars)\n\u001b[1;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49minterim\u001b[39m.\u001b[39;49mmaybe_merge_call(\n\u001b[0;32m    672\u001b[0m     functools\u001b[39m.\u001b[39;49mpartial(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distributed_apply, apply_state\u001b[39m=\u001b[39;49mapply_state),\n\u001b[0;32m    673\u001b[0m     strategy,\n\u001b[0;32m    674\u001b[0m     grads_and_vars,\n\u001b[0;32m    675\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[1;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39m  The return value of the `fn` call.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[1;32m---> 51\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(strategy, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   \u001b[39mreturn\u001b[39;00m distribution_strategy_context\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[0;32m     54\u001b[0m       fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:716\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply\u001b[1;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[39mwith\u001b[39;00m distribution\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39mcolocate_vars_with(var):\n\u001b[0;32m    713\u001b[0m   \u001b[39mwith\u001b[39;00m name_scope_only_in_function_or_graph(\n\u001b[0;32m    714\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m eagerly_outside_functions \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mupdate_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\n\u001b[0;32m    715\u001b[0m       var\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mname):\n\u001b[1;32m--> 716\u001b[0m     update_op \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39;49mextended\u001b[39m.\u001b[39;49mupdate(\n\u001b[0;32m    717\u001b[0m         var, apply_grad_to_update_var, args\u001b[39m=\u001b[39;49m(grad,), group\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    718\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39min_cross_replica_context():\n\u001b[0;32m    719\u001b[0m       \u001b[39m# In cross-replica context, extended.update returns a list of\u001b[39;00m\n\u001b[0;32m    720\u001b[0m       \u001b[39m# update ops from all replicas (group=False).\u001b[39;00m\n\u001b[0;32m    721\u001b[0m       update_ops\u001b[39m.\u001b[39mextend(update_op)\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2630\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   2627\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   2628\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2629\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2630\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(var, fn, args, kwargs, group)\n\u001b[0;32m   2631\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2632\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_ctx_update(\n\u001b[0;32m   2633\u001b[0m       var, fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3703\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   3700\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update\u001b[39m(\u001b[39mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[0;32m   3701\u001b[0m   \u001b[39m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[0;32m   3702\u001b[0m   \u001b[39m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[1;32m-> 3703\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_non_slot(var, fn, (var,) \u001b[39m+\u001b[39;49m \u001b[39mtuple\u001b[39;49m(args), kwargs, group)\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3709\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[1;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[0;32m   3705\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_non_slot\u001b[39m(\u001b[39mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[0;32m   3706\u001b[0m   \u001b[39m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[0;32m   3707\u001b[0m   \u001b[39m# once that value is used for something.\u001b[39;00m\n\u001b[0;32m   3708\u001b[0m   \u001b[39mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[1;32m-> 3709\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   3710\u001b[0m     \u001b[39mif\u001b[39;00m should_group:\n\u001b[0;32m   3711\u001b[0m       \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    594\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 595\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:699\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var\u001b[1;34m(var, grad)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mapply_state\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_apply_args:\n\u001b[0;32m    698\u001b[0m   apply_kwargs[\u001b[39m\"\u001b[39m\u001b[39mapply_state\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m apply_state\n\u001b[1;32m--> 699\u001b[0m update_op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resource_apply_dense(grad, var, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mapply_kwargs)\n\u001b[0;32m    700\u001b[0m \u001b[39mif\u001b[39;00m var\u001b[39m.\u001b[39mconstraint \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    701\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies([update_op]):\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:165\u001b[0m, in \u001b[0;36mAdam._resource_apply_dense\u001b[1;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[0;32m    162\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_slot(var, \u001b[39m'\u001b[39m\u001b[39mv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamsgrad:\n\u001b[1;32m--> 165\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mraw_ops\u001b[39m.\u001b[39;49mResourceApplyAdam(\n\u001b[0;32m    166\u001b[0m       var\u001b[39m=\u001b[39;49mvar\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m    167\u001b[0m       m\u001b[39m=\u001b[39;49mm\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m    168\u001b[0m       v\u001b[39m=\u001b[39;49mv\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m    169\u001b[0m       beta1_power\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mbeta_1_power\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    170\u001b[0m       beta2_power\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mbeta_2_power\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    171\u001b[0m       lr\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mlr_t\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    172\u001b[0m       beta1\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mbeta_1_t\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    173\u001b[0m       beta2\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mbeta_2_t\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    174\u001b[0m       epsilon\u001b[39m=\u001b[39;49mcoefficients[\u001b[39m'\u001b[39;49m\u001b[39mepsilon\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    175\u001b[0m       grad\u001b[39m=\u001b[39;49mgrad,\n\u001b[0;32m    176\u001b[0m       use_locking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_use_locking)\n\u001b[0;32m    177\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m   vhat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_slot(var, \u001b[39m'\u001b[39m\u001b[39mvhat\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py:400\u001b[0m, in \u001b[0;36mkwarg_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m args:\n\u001b[0;32m    396\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    397\u001b[0m       \u001b[39m'\u001b[39m\u001b[39m{f}\u001b[39;00m\u001b[39m only takes keyword args (possible keys: \u001b[39m\u001b[39m{kwargs}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    398\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mPlease pass these args as kwargs instead.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    399\u001b[0m       \u001b[39m.\u001b[39mformat(f\u001b[39m=\u001b[39mf\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, kwargs\u001b[39m=\u001b[39mf_argspec\u001b[39m.\u001b[39margs))\n\u001b[1;32m--> 400\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_training_ops.py:1426\u001b[0m, in \u001b[0;36mresource_apply_adam\u001b[1;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[0;32m   1424\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   1425\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1426\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[0;32m   1427\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[0;32m   1428\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7186\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7185\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7186\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: var and grad do not have the same shape[2,1] [2] [Op:ResourceApplyAdam]"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "inputs = keras.Input(shape=(2,))\n",
    "l = layers.Dense(1, activation='linear')(inputs)\n",
    "model = keras.Model(inputs=inputs, outputs=l)\n",
    "x = tf.Variable([[1.0, 2.0]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = model(x) ** 2\n",
    "\n",
    "grad = tape.gradient(y, x)\n",
    "print(grad)\n",
    "zipped = zip(grad, x)\n",
    "print(list(zipped))\n",
    "optimizer.apply_gradients(zip(grad, model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "s = [1, 2, 3, 4, 5]\n",
    "\n",
    "for i in range(len(t)):\n",
    "    tf.summary.scalar('t', t[i], step=i+1)\n",
    "    print(t[i])\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.40760604], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_label = tf.convert_to_tensor([2], dtype=tf.int64)\n",
    "y_hat = tf.convert_to_tensor([[1.0, 2.0, 3.0]], dtype=tf.float32)\n",
    "c = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=y_hat, labels=y_label)\n",
    "\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.40766755, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(-tf.math.log(0.6652))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2975074, 1.1448326, 0.       ], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = tf.constant([[2., -5., .5, -.1],\n",
    "                      [0., 0., 1.9, 1.4],\n",
    "                      [-100., 100., -100., -100.]])\n",
    "labels = tf.constant([0, 3, 1])\n",
    "tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07848619 0.07848619 0.5247504  0.3182772 ]\n"
     ]
    }
   ],
   "source": [
    "s = tf.math.softmax(logits, axis=1)[1].numpy()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.1448326, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(-tf.math.log(0.3182772))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "title_data = np.random.randint(2, size=(4))\n",
    "print(title_data.shape)\n",
    "print(title_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"model_8\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\vscodespace\\violet712.github.io\\my_algorithms\\test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mModel(x, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m inp \u001b[39m=\u001b[39m [[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m]]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model(inp)\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py:200\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInputs to a layer should be tensors. Got: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(input_spec):\n\u001b[1;32m--> 200\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m expects \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(input_spec)\u001b[39m}\u001b[39;00m\u001b[39m input(s),\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    201\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m but it received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m input tensors. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    202\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInputs received: \u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    203\u001b[0m \u001b[39mfor\u001b[39;00m input_index, (x, spec) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(inputs, input_spec)):\n\u001b[0;32m    204\u001b[0m   \u001b[39mif\u001b[39;00m spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Layer \"model_8\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>]"
     ]
    }
   ],
   "source": [
    "# this is a logistic regression in Keras\n",
    "x = keras.Input(shape=(2,))\n",
    "y = layers.Dense(16, activation='softmax')(x)\n",
    "model = keras.Model(x, y)\n",
    "\n",
    "inp = [[1, 2]]\n",
    "model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\vscodespace\\violet712.github.io\\my_algorithms\\test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m p \u001b[39m=\u001b[39m out(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(p)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "out = keras.Input(shape=(2,), name='out')\n",
    "x = [1, 2]\n",
    "x = x.numpy()\n",
    "p = out(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2 2 2 2 1 2 1 2 2]], shape=(1, 10), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "s = tf.random.categorical([[-100000000000000., 2., 3.]], num_samples=10)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.6931472 -0.6931472]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor([[1 1 1 0 0]], shape=(1, 5), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "samples = tf.random.categorical(tf.math.log([[0.5, 0.5]]), 5)\n",
    "\n",
    "print(tf.math.log([[0.5, 0.5]]))\n",
    "print(samples)\n",
    "print(samples[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,762\n",
      "Trainable params: 2,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32,)) \n",
    "x = layers.Dense(64, activation='relu')(inputs) \n",
    "outputs = layers.Dense(10)(x) \n",
    "mlp = keras.Model(inputs, outputs)\n",
    "\n",
    "print(mlp.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(keras.Model):    \n",
    "    def __init__(self, **kwargs):     \n",
    "        super(MLP, self).__init__(**kwargs)     \n",
    "        self.dense_1 = layers.Dense(64, activation='relu')     \n",
    "        self.dense_2 = layers.Dense(10)    \n",
    "    \n",
    "    def call(self, inputs):     \n",
    "        x = self.dense_1(inputs)     \n",
    "        return self.dense_2(x)  # Instantiate the model. mlp = MLP() # Necessary to create the model's state. # The model doesn't have a state until it's called at least once. _ = mlp(tf.zeros((1, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,762\n",
      "Trainable params: 2,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp=MLP.call(Input(shape=(32,)))\n",
    "mlp.build(input_shape=(None, 32))\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " title (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " body (InputLayer)              [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 64)     640000      ['title[0][0]']                  \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 64)     640000      ['body[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 128)          98816       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 32)           12416       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " tags (InputLayer)              [(None, 12)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 172)          0           ['lstm[0][0]',                   \n",
      "                                                                  'lstm_1[0][0]',                 \n",
      "                                                                  'tags[0][0]']                   \n",
      "                                                                                                  \n",
      " priority (Dense)               (None, 1)            173         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " department (Dense)             (None, 4)            692         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,392,097\n",
      "Trainable params: 1,392,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_tags = 12  # Number of unique issue tags\n",
    "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4  # Number of departments for predictions\n",
    "\n",
    "title_input = keras.Input(\n",
    "    shape=(None,), name=\"title\"\n",
    ")  # Variable-length sequence of ints\n",
    "body_input = keras.Input(shape=(None,), name=\"body\")  # Variable-length sequence of ints\n",
    "tags_input = keras.Input(\n",
    "    shape=(num_tags,), name=\"tags\"\n",
    ")  # Binary vectors of size `num_tags`\n",
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = layers.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = layers.Dense(1, name=\"priority\")(x)\n",
    "# Stick a department classifier on top of the features\n",
    "department_pred = layers.Dense(num_departments, name=\"department\")(x)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = keras.Model(\n",
    "    inputs=[title_input, body_input, tags_input],\n",
    "    outputs=[priority_pred, department_pred],\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got: <keras.layers.core.dense.Dense object at 0x000001C702E94A90>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\vscodespace\\violet712.github.io\\my_algorithms\\test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m inputs \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39m784\u001b[39m,), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdigits\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m common \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDense(\u001b[39m64\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m actor \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mDense(\u001b[39m1\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msigmoid\u001b[39;49m\u001b[39m'\u001b[39;49m)(common)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m critic \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m)(common)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mModel(inputs\u001b[39m=\u001b[39minputs, outputs\u001b[39m=\u001b[39m[actor, critic])\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_spec.py:197\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m inputs:\n\u001b[0;32m    192\u001b[0m   \u001b[39m# Having a shape/dtype is the only commonality of the various tensor-like\u001b[39;00m\n\u001b[0;32m    193\u001b[0m   \u001b[39m# objects that may be passed. The most common kind of invalid type we are\u001b[39;00m\n\u001b[0;32m    194\u001b[0m   \u001b[39m# guarding for is a Layer instance (Functional API), which does not\u001b[39;00m\n\u001b[0;32m    195\u001b[0m   \u001b[39m# have a `shape` attribute.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInputs to a layer should be tensors. Got: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(input_spec):\n\u001b[0;32m    200\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m expects \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(input_spec)\u001b[39m}\u001b[39;00m\u001b[39m input(s),\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    201\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m but it received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m input tensors. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    202\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInputs received: \u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <keras.layers.core.dense.Dense object at 0x000001C702E94A90>"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name='digits')\n",
    "common = layers.Dense(64, activation='relu')\n",
    "actor = layers.Dense(1, activation='sigmoid')(common)\n",
    "critic = layers.Dense(1)(common)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=[actor, critic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 10)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(range(10))\n",
    "\n",
    "for i in range(10):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\vscodespace\\violet712.github.io\\my_algorithms\\test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# dy = 2x * dx\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m dy_dx \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(y, x)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/vscodespace/violet712.github.io/my_algorithms/test.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(dy_dx\u001b[39m.\u001b[39;49mnumpy())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  # tape.watch(x)\n",
    "  y = x**2\n",
    "\n",
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.one_hot([0], depth=4)\n",
    "s = tf.Variable(s)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(s)\n",
    "    loss = tf.reduce_sum(s)\n",
    "    \n",
    "grad = tape.gradient(loss, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[var.name for var in tape.watched_variables()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(1,))\n",
    "outputs = layers.Dense(10)(inputs)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deep Q-Network Q(a, s)\n",
    "-----------------------\n",
    "TD Learning, Off-Policy, e-Greedy Exploration (GLIE).\n",
    "\n",
    "Q(S, A) <- Q(S, A) + alpha * (R + lambda * Q(newS, newA) - Q(S, A))\n",
    "delta_w = R + lambda * Q(newS, newA)\n",
    "\n",
    "See David Silver RL Tutorial Lecture 5 - Q-Learning for more details.\n",
    "\n",
    "Reference\n",
    "----------\n",
    "original paper: https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf\n",
    "EN: https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0#.5m3361vlw\n",
    "CN: https://zhuanlan.zhihu.com/p/25710327\n",
    "\n",
    "Note: Policy Network has been proved to be better than Q-Learning, see tutorial_atari_pong.py\n",
    "\n",
    "Environment\n",
    "-----------\n",
    "# The FrozenLake v0 environment\n",
    "https://gym.openai.com/envs/FrozenLake-v0\n",
    "The agent controls the movement of a character in a grid world. Some tiles of\n",
    "the grid are walkable, and others lead to the agent falling into the water.\n",
    "Additionally, the movement direction of the agent is uncertain and only partially\n",
    "depends on the chosen direction. The agent is rewarded for finding a walkable\n",
    "path to a goal tile.\n",
    "SFFF       (S: starting point, safe)\n",
    "FHFH       (F: frozen surface, safe)\n",
    "FFFH       (H: hole, fall to your doom)\n",
    "HFFG       (G: goal, where the frisbee is located)\n",
    "The episode ends when you reach the goal or fall in a hole. You receive a reward\n",
    "of 1 if you reach the goal, and zero otherwise.\n",
    "\n",
    "Prerequisites\n",
    "--------------\n",
    "tensorflow>=2.0.0a0\n",
    "tensorlayer>=2.0.0\n",
    "\n",
    "To run\n",
    "-------\n",
    "python tutorial_DQN.py --train/test\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import argparse\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "\n",
    "# add arguments in command  --train/test\n",
    "# 关于argparase的应用，可以看看我这篇知乎专栏：\n",
    "# 小段文讲清argparse模块基本用法[小番外]\n",
    "# https://zhuanlan.zhihu.com/p/111010774\n",
    "# 注意：原代码默认为test，我改为了train。\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Train or test neural net motor controller.')\n",
    "parser.add_argument('--train', dest='train', action='store_true', default=True)\n",
    "parser.add_argument('--test', dest='test', action='store_true', default=False)\n",
    "args = parser.parse_args()\n",
    "\n",
    "tl.logging.set_verbosity(tl.logging.DEBUG)\n",
    "\n",
    "#####################  hyper parameters  ####################\n",
    "lambd = .99             # 折扣率(decay factor)\n",
    "e = 0.1                 # epsilon-greedy算法参数，越大随机性越大，越倾向于探索行为。\n",
    "num_episodes = 10000    # 迭代次数\n",
    "render = False          # 是否渲染游戏\n",
    "running_reward = None\n",
    "\n",
    "##################### DQN ##########################\n",
    "\n",
    "## 把分类的数字表示，变成onehot表示。\n",
    "# 例如有4类，那么第三类变为：[0,0,1,0]的表示。\n",
    "\n",
    "\n",
    "def to_one_hot(i, n_classes=None):\n",
    "    a = np.zeros(n_classes, 'uint8')    # 这里先按照分类数量构建一个全0向量\n",
    "    a[i] = 1                            # 然后点亮需要onehot的位数。\n",
    "    return a\n",
    "\n",
    "\n",
    "## Define Q-network q(a,s) that ouput the rewards of 4 actions by given state, i.e. Action-Value Function.\n",
    "# encoding for state: 4x4 grid can be represented by one-hot vector with 16 integers.\n",
    "def get_model(inputs_shape):\n",
    "    '''\n",
    "    定义Q网络模型：\n",
    "    1. 注意输入的shape和输出的shape\n",
    "    2. W_init和b_init是模型在初始化的时候，控制初始化参数的随机。该代码中用正态分布，均值0，方差0.01的方式初始化参数。\n",
    "    '''\n",
    "    ni = tl.layers.Input(inputs_shape, name='observation')\n",
    "    nn = tl.layers.Dense(4, act=None, W_init=tf.random_uniform_initializer(\n",
    "        0, 0.01), b_init=None, name='q_a_s')(ni)\n",
    "    return tl.models.Model(inputs=ni, outputs=nn, name=\"Q-Network\")\n",
    "\n",
    "\n",
    "def save_ckpt(model):  # save trained weights\n",
    "    '''\n",
    "    保存参数\n",
    "    '''\n",
    "    tl.files.save_npz(model.trainable_weights, name='dqn_model.npz')\n",
    "\n",
    "\n",
    "def load_ckpt(model):  # load trained weights\n",
    "    '''\n",
    "    加载参数\n",
    "    '''\n",
    "    tl.files.load_and_assign_npz(name='dqn_model.npz', network=model)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    qnetwork = get_model([None, 16])  # 定义inputshape[None,16]。16是state数量\n",
    "    qnetwork.train()  # 调用tensorlayer的时候，需要标注这个模型是否可以训练。(再次吐槽tenorlayers...)\n",
    "    train_weights = qnetwork.trainable_weights  # 模型的参数\n",
    "\n",
    "    optimizer = tf.optimizers.SGD(learning_rate=0.1)  # 定义优化器\n",
    "    env = gym.make('FrozenLake-v0')  # 定义环境\n",
    "\n",
    "    # ======开始训练=======\n",
    "    if args.train:\n",
    "        t0 = time.time()\n",
    "        for i in range(num_episodes):\n",
    "            ## 重置环境初始状态\n",
    "            s = env.reset()\n",
    "            rAll = 0\n",
    "            for j in range(99):             # 最多探索99步。因为环境状态比较少，99步一般也够探索到最终状态了。\n",
    "                if render:\n",
    "                    env.render()\n",
    "\n",
    "                ## 把state放入network，计算Q值。\n",
    "                ## 注意，这里先把state进行onehote处理，这里注意解释下什么是onehot\n",
    "                ## 输出，这个状态下，所有动作的Q值，也就是说，是一个[None,4]大小的矩阵\n",
    "                allQ = qnetwork(np.asarray(\n",
    "                    [to_one_hot(s, 16)], dtype=np.float32)).numpy()\n",
    "\n",
    "                # 在矩阵中找最大的Q值的动作\n",
    "                a = np.argmax(allQ, 1)\n",
    "\n",
    "                # e-Greedy：如果小于epsilon，就智能体随机探索。否则，就用最大Q值的动作。\n",
    "                if np.random.rand(1) < e:\n",
    "                    a[0] = env.action_space.sample()\n",
    "\n",
    "                # 输入到环境，获得下一步的state，reward，done\n",
    "                s1, r, d, _ = env.step(a[0])\n",
    "\n",
    "                # 把new-state 放入，预测下一个state的**所有动作**的Q值。\n",
    "                Q1 = qnetwork(np.asarray(\n",
    "                    [to_one_hot(s1, 16)], dtype=np.float32)).numpy()\n",
    "\n",
    "                ##=======计算target=======\n",
    "                ## 构建更新target：\n",
    "                #    Q'(s,a) <- Q(s,a) + alpha(r + lambd * maxQ(s',a') - Q(s, a))\n",
    "                maxQ1 = np.max(Q1)          # 下一个状态中最大Q值.\n",
    "                # 用allQ(现在状态的Q值)构建更新的target。因为只有被选择那个动作才会被更新到。\n",
    "                targetQ = allQ\n",
    "                targetQ[0, a[0]] = r + lambd * maxQ1\n",
    "\n",
    "                ## 利用自动求导 进行更新。\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # 把s放入到Q网络，计算_qvalues。\n",
    "                    _qvalues = qnetwork(np.asarray(\n",
    "                        [to_one_hot(s, 16)], dtype=np.float32))\n",
    "                    #_qvalues和targetQ的差距就是loss。这里衡量的尺子是mse\n",
    "                    _loss = tl.cost.mean_squared_error(\n",
    "                        targetQ, _qvalues, is_mean=False)\n",
    "                # 同梯度带求导对网络参数求导\n",
    "                grad = tape.gradient(_loss, train_weights)\n",
    "                # 应用梯度到网络参数求导\n",
    "                optimizer.apply_gradients(zip(grad, train_weights))\n",
    "\n",
    "                # 累计reward，并且把s更新为newstate\n",
    "                rAll += r\n",
    "                s = s1\n",
    "\n",
    "                #更新epsilon，让epsilon随着迭代次数增加而减少。\n",
    "                #目的就是智能体越来越少进行“探索”\n",
    "                if d == True:\n",
    "                    e = 1. / ((i / 50) + 10)\n",
    "                    break\n",
    "\n",
    "            ## 这里的running_reward用于记载每一次更新的总和。为了能够更加看清变化，所以大部分是前面的。只有一部分是后面的。\n",
    "            running_reward = rAll if running_reward is None else running_reward * 0.99 + rAll * 0.01\n",
    "            # print(\"Episode [%d/%d] sum reward: %f running reward: %f took: %.5fs \" % \\\n",
    "            #     (i, num_episodes, rAll, running_reward, time.time() - episode_time))\n",
    "            print('Episode: {}/{}  | Episode Reward: {:.4f} | Running Average Reward: {:.4f}  | Running Time: {:.4f}'\n",
    "                  .format(i, num_episodes, rAll, running_reward,  time.time()-t0))\n",
    "        save_ckpt(qnetwork)  # save model\n",
    "\n",
    "    ##============这部分是正式游戏了========\n",
    "    # 这部分就不讲解了，和训练一样。只是少了epsilon-greedy。\n",
    "    if args.test:\n",
    "        t0 = time.time()\n",
    "        load_ckpt(qnetwork)  # load model\n",
    "        for i in range(num_episodes):\n",
    "            ## Reset environment and get first new observation\n",
    "            episode_time = time.time()\n",
    "            s = env.reset()  # observation is state, integer 0 ~ 15\n",
    "            rAll = 0\n",
    "            for j in range(99):  # step index, maximum step is 99\n",
    "                if render:\n",
    "                    env.render()\n",
    "\n",
    "                ## Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "                allQ = qnetwork(np.asarray(\n",
    "                    [to_one_hot(s, 16)], dtype=np.float32)).numpy()\n",
    "                a = np.argmax(allQ, 1)  # no epsilon, only greedy for testing\n",
    "\n",
    "                ## Get new state and reward from environment\n",
    "                s1, r, d, _ = env.step(a[0])\n",
    "                rAll += r\n",
    "                s = s1\n",
    "                ## Reduce chance of random action if an episode is done.\n",
    "                if d == True:\n",
    "                    #e = 1. / ((i / 50) + 10)  # reduce e, GLIE: Greey in the limit with infinite Exploration\n",
    "                    break\n",
    "\n",
    "            ## Note that, the rewards here with random action\n",
    "            running_reward = rAll if running_reward is None else running_reward * 0.99 + rAll * 0.01\n",
    "            # print(\"Episode [%d/%d] sum reward: %f running reward: %f took: %.5fs \" % \\\n",
    "            #     (i, num_episodes, rAll, running_reward, time.time() - episode_time))\n",
    "            print('Episode: {}/{}  | Episode Reward: {:.4f} | Running Average Reward: {:.4f}  | Running Time: {:.4f}'\n",
    "                  .format(i, num_episodes, rAll, running_reward,  time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.random.randint(0, 2, size=(2, 3))\n",
    "y_pred = np.random.random(size=(2, 3))\n",
    "loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "assert np.array_equal(\n",
    "    loss.numpy(), np.mean(np.square(y_true - y_pred), axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.zeros((6,))\n",
    "c = tf.ones((2,))\n",
    "b = a\n",
    "c = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
