{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Exploration for Reinforcement Learning with General Value Function Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "> We propose a model-free reinforcement learning algorithm inspired by the popular randomized least squares value iteration (RLSVI) algorithm as well as the optimism principle. Unlike existing upper-confidence-bound (UCB) based approaches, which are often computationally intractable, our algorithm drives exploration by simply perturbing the training data with judiciously chosen i.i.d. scalar noises. To attain optimistic value function estimation without resorting to a UCB-style bonus, we introduce an optimistic reward sampling procedure. When the value functions can be represented by a function class $\\mathcal{F}$, our algorithm achieves a worst-case regret bound of $\\widetilde{O}(\\mathrm{poly}(d_EH)\\sqrt{T})$ where $T$ is the time elapsed, $H$ is the planning horizon and $d_E$ is the $\\textit{eluder dimension}$ of $\\mathcal{F}$. In the linear setting, our algorithm reduces to LSVI-PHE, avariant of RLSVI, that enjoys an $\\widetilde{\\mathcal{O}}(\\sqrt{d^3H^3T})$ regret. We complement the theory with an empirical evaluation across known difficult exploration tasks.\n",
    "\n",
    "受到普遍的随机化最小二乘值迭代算法和最优原则的启发,我们提出了一个免模型的强化学习算法.与现存的计算困难的UCB算法不同,我们的算法通过明智地选择独立同分布的标量噪声以简单地扰动训练数据.为了不使用UCB风格的方法获得最优价值函数估计,我们介绍一个最优奖励采样程序.当价值函数可以由一个函数类 $\\mathcal{F}$ 表示时,\n",
    "\n",
    "> **regret bound:** Reinforcement Learning models are often measured relative to each other and sometimes relative to optimal behavior.\n",
    "> - Regret is a common measure of performance for Reinforcement Learning systems.\n",
    "> - Reinforcement Learning model performance is stochastic. Thus, is better to run the same model many times to estimate the distribution for performance. From that distribution, bounds can be estimated. Those bounds are similar to confidence intervals for scalar parameter estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2638d182245c591c0c7650a148f9b4622aaf18b8cff9e48ecf203e602cb4653c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
